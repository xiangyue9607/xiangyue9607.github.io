<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Xiang Yue - AI Researcher at Meta, specializing in Natural Language Processing and Large Language Models">
    <meta name="keywords" content="Xiang Yue, NLP, LLMs, Large Language Models, Meta, Research, AI, Machine Learning">
    <meta name="author" content="Xiang Yue">

    <!-- Open Graph / Facebook -->
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://xiangyue9607.github.io/">
    <meta property="og:title" content="Xiang Yue - AI Researcher at Meta">
    <meta property="og:description" content="AI Researcher at Meta, specializing in Natural Language Processing and Large Language Models">
    <meta property="og:image" content="https://xiangyue9607.github.io/images/yuexiang_profile.jpg">

    <!-- Twitter -->
    <meta property="twitter:card" content="summary_large_image">
    <meta property="twitter:url" content="https://xiangyue9607.github.io/">
    <meta property="twitter:title" content="Xiang Yue - AI Researcher at Meta">
    <meta property="twitter:description" content="AI Researcher at Meta, specializing in Natural Language Processing and Large Language Models">
    <meta property="twitter:image" content="https://xiangyue9607.github.io/images/yuexiang_profile.jpg">
    <meta property="twitter:creator" content="@xiangyue96">

    <title>Xiang Yue</title>

    <!-- Favicon -->
    <link rel="apple-touch-icon" sizes="180x180" href="images/icon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="images/icon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="images/icon/favicon-16x16.png">
    <link rel="manifest" href="images/icon/site.webmanifest">

    <!-- Stylesheet -->
    <link rel="stylesheet" href="stylesheets/styles.css">

    <!-- Structured Data -->
    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "Person",
        "name": "Xiang Yue",
        "alternateName": "岳翔",
        "url": "https://xiangyue9607.github.io/",
        "image": "https://xiangyue9607.github.io/images/yuexiang_profile.jpg",
        "jobTitle": "AI Researcher",
        "worksFor": {
            "@type": "Organization",
            "name": "Meta",
            "department": "Meta Superintelligence Labs (MSL)"
        },
        "alumniOf": [
            {
                "@type": "Organization",
                "name": "Carnegie Mellon University"
            },
            {
                "@type": "Organization",
                "name": "The Ohio State University"
            },
            {
                "@type": "Organization",
                "name": "Wuhan University"
            }
        ],
        "email": "xiangyue.work@gmail.com",
        "sameAs": [
            "https://scholar.google.com/citations?hl=en&user=4jX_dI8AAAAJ",
            "https://github.com/xiangyue9607",
            "https://www.linkedin.com/in/xiang-yue-0704/",
            "https://twitter.com/xiangyue96"
        ],
        "knowsAbout": [
            "Natural Language Processing",
            "Large Language Models",
            "Machine Learning",
            "Artificial Intelligence",
            "Computer Science Research"
        ]
    }
    </script>
</head>
<body>

<nav>
    <div class="nav-container">
        <a href="index.html">Home</a>
        <a href="publication.html">Papers</a>
    </div>
</nav>

<div class="container">
    <div class="hero">
        <div class="profile-section">
            <img class="profile-image" src="images/yuexiang_profile.jpg" alt="Xiang Yue">
            <div class="profile-info">
                <h1>Xiang Yue</h1>
                <p>岳翔 (Pronounced as <i>"Shiang Yoo-eh"</i>)</p>
                <p>xiangyue.work@gmail.com</p>
                <div class="links">
                    <a href="https://scholar.google.com/citations?hl=en&user=4jX_dI8AAAAJ" target="_blank">Google Scholar</a>
                    <a href="https://github.com/xiangyue9607" target="_blank">Github</a>
                    <a href="https://www.linkedin.com/in/xiang-yue-0704/" target="_blank">LinkedIn</a>
                    <a href="https://twitter.com/xiangyue96" target="_blank">Twitter</a>
                </div>
            </div>
        </div>

        <div class="professional-summary">
            <p>I am an AI researcher at Meta Superintelligence Labs (MSL). Before joining Meta, I spent two wonderful years at Carnegie Mellon University (CMU) as a postdoctoral researcher, working with <a href="https://www.phontron.com/" target="_blank">Prof. Graham Neubig</a> on natural language processing (NLP) and large language models (LLMs).</p>

            <p>I received my Ph.D. from The Ohio State University's <a href="https://twitter.com/osunlp" target="_blank">OSU NLP Group</a>, where I was advised by <a href="http://web.cse.ohio-state.edu/~sun.397/" target="_blank">Prof. Huan Sun</a> and <a href="https://ysu1989.github.io/" target="_blank">Prof. Yu Su</a>. I completed my B.S. in Computer Science at Wuhan University.</p>
        </div>

        <h2>Recent Papers</h2>
        <ul class="talks-list">
            <li><a href="https://arxiv.org/abs/2311.16502" target="_blank">MMMU</a> / <a href="https://arxiv.org/abs/2409.02813" target="_blank">MMMU-Pro</a> / <a href="https://arxiv.org/abs/2406.01574/" target="_blank">MMLU-Pro</a>: A series of benchmarks for multimodal and language reasoning</li>

            <li><a href="https://arxiv.org/abs/2512.07783" target="_blank">On the Interplay of Pre-Training, Mid-Training, and RL on Reasoning Language Models</a></li>

            <li><a href="https://arxiv.org/pdf/2502.03373" target="_blank">Demystifying Long Chain-of-Thought Reasoning in LLMs</a></li>

            <li><a href="https://arxiv.org/abs/2507.00432" target="_blank">Does Math Reasoning Improve General LLM Capabilities? Understanding Transferability of LLM Reasoning</a></li>

            <li><a href="https://tiger-ai-lab.github.io/MAmmoTH2/" target="_blank">MAmmoTH2: Scaling Instructions from the Web</a></li>

            <li><a href="https://arxiv.org/abs/2405.15071" target="_blank">Grokked Transformers are Implicit Reasoners: A Mechanistic Journey to the Edge of Generalization</a></li>

        </ul>

        <h2>Recent Talks and Media</h2>
        <ul class="talks-list">
            

            <li><a href="https://benchmarking.science/" target="_blank">[NeurIPS 2025 Tutorial] The Science of Benchmarking</a> <a href="https://benchmarking.science/slides.pdf" target="_blank">[Slides]</a></li>

            <li>Rethinking LLM Reasoning <a href="pdf/Rethinking_LLM_Reasoning.pdf" target="_blank">[Slides]</a></li>

            <li>Learning to Reason with LLMs <a href="pdf/Learning_to_Reason_with_LLMs.pdf" target="_blank">[Slides]</a></li>

            <li><a href="https://synth-data-acl.github.io/" target="_blank">[ACL 2025 Tutorial] Synthetic Data in the Era of LLMs</a> <a href="https://synth-data-acl.github.io/static/slides/slides.pdf" target="_blank">[Slides]</a></li>

            <li><a href="https://www.nature.com/articles/d41586-025-00110-6" target="_blank">[Nature] How should we test AI for human-level intelligence? OpenAI's o3 electrifies quest</a></li>
        </ul>
    </div>

    <div class="footer">
        Last Updated: 12/2025
    </div>
</div>

</body>
</html>
