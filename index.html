<!DOCTYPE html>
<html>
<head>
    <meta content="width=device-width,height=device-height,initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.5, user-scalable=yes"
          name="viewport">
    <meta charset="utf-8">
    <title>Xiang Yue's Homepage</title>
    <link rel="stylesheet" type="text/css" href="./stylesheets/styles.css">
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.3.1/semantic.css">
    <link rel="apple-touch-icon" sizes="180x180" href="images/icon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="images/icon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="images/icon/favicon-16x16.png">
    <link rel="manifest" href="images/icon/site.webmanifest">
    <script src="./stylesheets/jquery.js"></script>
    <script src="./stylesheets/semantic.js"></script>
</head>
<body>

<!-- header -->
<div class="ui fixed inverted menu">
    <div class="ui container">
        <a href="index.html" class="description item">Home</a>
        <a href="publication.html" class="item">Publications</a>
        <a href="talk.html" class="item">Talks</a>
        <a href="teaching.html" class="item">Teaching</a>
    </div>
</div>

<!-- home -->
<div class="ui main container">
    <br><br><br>
    <div class="ui stackable grid">
        <div class="twelve wide column">
            <div class="ui stackable grid">
                <div class="four wide column">
                    <img class="ui small circular image" src="images/yuexiang_profile.jpg" style="margin: 20px;">
                </div>
                <div class="twelve wide column">
                    <h1 class="ui header">Xiang Yue</h1>
                    <p>
                        (Pronounced as <i>"Shiang Yoo-eh"</i>, Â≤≥Áøî)
                    </p>
                    <p>Postdoctoral Researcher<br>
                        <a href="https://www.lti.cs.cmu.edu/" target="_blank">Language Technologies Institute</a><br>
                        <a href="https://www.cs.cmu.edu/" target="_blank">School of Computer Science</a><br>
                        <a href="https://www.cmu.edu/" target="_blank">Carnegie Mellon University</a>
                    </p>
                    <p>Email: xyue2@andrew.cmu.edu</p>
                    <p>
                        <a href="https://scholar.google.com/citations?hl=en&user=4jX_dI8AAAAJ&view_op=list_works&sortby=pubdate" target="_blank"><i class="google icon"></i>Google Scholar</a>
                        <a href="https://github.com/xiangyue9607" target="_blank"><i class="github icon"></i>Github</a>
                        <a href="https://www.linkedin.com/in/xiang-yue-0704/" target="_blank"><i class="linkedin icon"></i>Linkedin</a>
                        <a href="https://twitter.com/xiangyue96" target="_blank"><i class="twitter icon"></i>Twitter</a>
                        <a href="images/wechat.jpg" target="_blank"><i class="weixin icon"></i>Wechat</a>
                    </p>
                </div>
            </div>

            <div class="ui section divider"></div>

            <div class="ui text container">
                <h2 class="ui header" id="bio">Bio</h2>
                <p>
                    I am a postdoctoral researcher at CMU working with <a href="https://www.phontron.com/" target="_blank">Prof. Graham Neubig</a> on natural language processing (NLP) and large language models (LLMs).
                
                    I obtained my Ph.D. from The Ohio State University <a href="https://twitter.com/osunlp">(OSU-NLP-Group)</a>, where I was trained by <a href="http://web.cse.ohio-state.edu/~sun.397/" target="_blank">Prof. Huan Sun</a> and <a href="https://ysu1989.github.io/" target="_blank">Prof. Yu Su</a>. 

                    I also collaborate closely with <a href="https://wenhuchen.github.io/">Prof. Wenhu Chen</a> at University of Waterloo.

                    I received my B.S. in Computer Science from Wuhan University</a> in 2018.
                
                </p>
            </div>


          

            <br>

            <!-- <div class="ui text container">
                <img src="images/neurips_poster_summary.png" alt="NeurIPS Poster Summary" style="display: block; margin: 0 auto; max-width: 100%; height: auto;">
            </div>

            <br> -->

            <div class="ui text container">

                My research aims to understand and enhance the reasoning capabilities of LLMs across different modalities and contexts while improving their responsibility and reliability.
                <ul>
                    <li> <b>Understanding LLMs' reasoning through rigorous evaluation and benchmarking</b>. 
                    <ul>
                        <li>Representative Work:
                            <a href="https://arxiv.org/abs/2311.16502">MMMU</a> (<a href="https://arxiv.org/abs/2409.02813">MMMU-Pro)</a>: the commonly used multimodal language model evaluation suite, including both open-source community (1.4M Downloads on <a href="https://huggingface.co/datasets/MMMU/MMMU">Huggingface</a>) and industrial leading AI models (e.g., <a href="https://openai.com/index/hello-gpt-4o/">OpenAI GPT</a>, <a href="https://blog.google/technology/ai/google-gemini-ai/#capabilities">Google Gemini</a>, <a href="https://www.anthropic.com/news/claude-3-5-sonnet">Anthropic Claude</a>, <a href="https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/">Meta Llama</a>, <a href="https://qwenlm.github.io/blog/qwen2-vl/">Alibaba Qwen</a>, and <a href="https://mmmu-benchmark.github.io/#leaderboard"> others</a>).  </li>
                        </li>
                        <li>
                            Other Major Contributed Projects: 
                            <a href="https://arxiv.org/abs/2405.15071">GrokkedTransformer</a> (NeurIPS 2024),
                            <a href="https://arxiv.org/abs/2406.01574/">MMLU-Pro</a> (NeurIPS 2024 Spotlight), <a href="https://mixeval.github.io/">MixEval</a> (NeurIPS 2024), <a href="https://tiger-ai-lab.github.io/MEGA-Bench/">MEGA-Bench</a>, <a href="https://visualwebbench.github.io/">ViusalWebBench</a> (COLM 2024) </li>
                        </li>
                    </ul>
                    
                    </li>
                    <li> <b>Improving LLMs' reasoning capabilities with synthetic data generation techniques</b>. I love <i>simple, 
                        scalable and cost-effective</i> data solutions and enjoy pushing the boundary of state-of-the-arts while open-sourcing everything I build.
                        <ul>
                            <li>Representative Work: <a href="https://tiger-ai-lab.github.io/MAmmoTH/" target="_blank">MAmmoTH</a> and <a href="https://tiger-ai-lab.github.io/MAmmoTH2/" target="_blank">MAmmoTH2</a>: Strong reasoning models achieving SoTA in 2023 and 2024 by scaling up reasoning <i>rationales</i> from different sources. Notable, MAmmoTH2's <a href="https://huggingface.co/datasets/TIGER-Lab/WebInstructSub" target="_blank">10 million synthetic instructions</a> achieve performance comparable to Meta Llama 3 Instruct, which relies on 10 million human-annotated examples. </li>
                            <li>Other Major Contributed Projects: 
                                <a href="https://neulab.github.io/Pangea/">Pangea</a> (SoTA open-source multilingual multimodal model on both English and Multilingual evaluations), <a href="https://opencodeinterpreter.github.io/">OpenCodeInterpreter</a> (ACL 2024 Findings; 90+ accuracy on HumanEval with 7B size), 
                                <a href="https://mammoth-vl.github.io/">MAmmoTH-VL</a> (SoTA open-source multimodal model), <a href="https://neulab.github.io/MultiUI/">MultiUI</a> (7M multimodal GUI understanding and agent data samples)
                            </li>
                        </ul>
                
                    </li>

                    <li> <b>Designing responsible and inclusive AI models</b> cover different aspects (e.g., Privacy, Attribution, Multilinguality) for real-world applications (e.g., Healthcare). </li>
                    <ul>
                        <li>Privacy: LLMs with Differential Privacy (DP) (<a href="https://arxiv.org/abs/2210.14348">ACL'23 Best Paper Honorable Mention</a>, <a href="https://arxiv.org/pdf/2309.06746">CCS'23</a>, <a href="https://arxiv.org/abs/2106.01221">ACL'21</a>), LLMs Unlearning (<a href="https://arxiv.org/abs/2402.15159">ACL'24</a>) </li>

                        </li>
                        <li>Attribution: Attribution evaluation in retrieval-augmented generation (RAG) (<a href="https://arxiv.org/abs/2305.06311">EMNLP'23</a>, <a href="https://arxiv.org/abs/2402.15089">ACL'24</a>); <a href="https://huggingface.co/spaces/TIGER-Lab/ScholarCopilot">ScholarCopilot</a> (academic writing assistant with BibTeX) </li>
                        </li> 
                        <li>
                            Multilinguality: Multilingual multimodal modeling (<a href="https://neulab.github.io/Pangea/">Pangea</a>) and evaluation (<a href="https://arxiv.org/pdf/2410.17250">JMMMU</a>)
                        </li>
                        <li>Healthcare: Medical Images (<a href="https://aimedlab.github.io/PULSE/" target="_blank">ECG Multimodal LLM)</a>, Clinical QA (IEEE BIBM'21 Best Paper, ACL'20) </li>

                        </li>
                </ul>
            </div>

            <div class="ui text container">
                <h2 class="ui header" id="news">What's New</h2>
                <ul>
                    <li>[May 2025] Three papers have been accepted to ICML 2025!</li>
                    <li>[April 2025]  <a href="https://arxiv.org/pdf/2502.03373"> Demystifying long CoT reasoning in LLMs</a> got a üèÜ Best Paper Award at <a href="https://fm-wild-community.github.io/">ICLR 2025 Workshop on
Foundation Models in the Wild</a>!  </li>
                    <li>[Jan 2025] Six papers have been accepted to ICLR 2025! </li>
                    <li>[Dec 2024] ‚úàÔ∏è Attending NeurIPS 2024 and presenting four papers: <a href="https://arxiv.org/abs/2405.03548">MAmmoTH2</a>, <a href="https://mixeval.github.io/">MixEval</a>, <a href="https://arxiv.org/abs/2406.01574/">MMLU-Pro</a>, and <a href="https://arxiv.org/abs/2405.15071">Grokked Transformers! Ping me if you want a coffee chat!</b>
                    </li>
                    <li>[Oct 2024] ‚úàÔ∏è Attending COLM 2024 and presenting <a href="https://visualwebbench.github.io/">VisualWebBench</a>!
                    </li>
                    <li>[Sept 2024] ‚úàÔ∏è Attending <a href="https://genai-workshop.cs.umass.edu/" target="_blank">Generative AI Rising Star Workshop at UMASS</a>. </li>
                    <li>[Jun 2024] ‚úàÔ∏è Attending CVPR 2024 and presenting MMMU <a href="./pdf/MMMU_CVPR2024.pdf" target="_blank">[Slides]</a></li>
                    <li>[May 2024] 6 papers (3 main + 3 findings) have been accepted to ACL 2024!</li>
                    <li>[March 2024] Honored to receive the <a href="https://carnegiebosch.cmu.edu/news/2024/10/24-xiang-yue-cbi-fellow.html" target="_blank">2024 Carnegie Bosch Postdoctoral Fellowship</a> and started my postdoc at CMU LTI!</li>
                    <li>[Oct 2023] Two papers on "Evaluating Attribution" and "Evaluating Reasoning" accepted to EMNLP 2023 </li>
                    <li>[July 2023] Paper on <a href="https://arxiv.org/abs/2210.14348">Synthetic Text Generation with Differential Privacy</a> received an Honorable Mention at ACL 2023</li>
                    <li>[May 2023] Honored to receive the 2023 CSE Graduate Research Award and the <a href="https://cse.osu.edu/news/2023/06/cse-phd-student-wins-college-engineering-graduate-award">2023 College of Engineering Exemplary Graduate Student Researcher Award</a> at Ohio State</li>
                </ul>
            </div>
        </div>

        <div class="four wide column">
            <a href="https://twitter.com/xiangyue96?ref_src=twsrc%5Etfw" class="twitter-follow-button" data-show-count="false">Follow @xiangyue96</a>
            <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
            <a class="twitter-timeline" data-height="1000" href="https://twitter.com/xiangyue96?ref_src=twsrc%5Etfw" ">Tweets by xiangyue96</a>
            <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
            <div style="display: flex; justify-content: center; margin-top: 5%;">
                <a href="https://mapmyvisitors.com/web/1bw0f" title="Visit tracker">
                  <img src="https://mapmyvisitors.com/map.png?d=l2PBJ1PhcW8FCh7bD9PMgAJUBCQ_cYPIOTZam_ZychU&cl=ffffff" " />
                </a>
            </div>
        </div>
    </div>

    <div class="ui section divider"></div>
    <p>Last Updated: 12/2024</p>
    </div>
</div>
</body>
</html>
